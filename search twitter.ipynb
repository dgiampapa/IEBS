{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **IEBS - Proyecto Final**\n",
        "\n",
        "Este notebook se encarga a traves de las APi de twitter buscar los tweets de los diferentes bancos a ser evaluados. Con esto se genera un archivo csv de los tweets y de los usuarios. \n",
        "\n",
        "* Se incluyo la limpieza de los datos de text, para esto se incluyeron unas librerias nuevas que realizan este proceso. Se creo la funcion data_cleaning\n",
        "\n",
        "Se generan 3 archivos:\n",
        "\n",
        "* {id}.csv = Contine los datos de ese ID\n",
        "\n",
        "* cleaning-\n",
        "\n",
        "```\n",
        "# Esto tiene formato de cÃ³digo\n",
        "```\n",
        "\n",
        "{id}.csv = Contiene los datos de ese ID con el text limpio \n",
        "\n",
        "* user-{id}.csv = Contiene los datos de los usuarios para los tweets buscados de ese id"
      ],
      "metadata": {
        "id": "58NKyYXscuKv"
      },
      "id": "58NKyYXscuKv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalacion de librerias\n",
        "\n",
        "Instalacion de las librerias opcionales que son necesarias para la limpieza de los datos. Se ejecuta una sola vez en el notebook."
      ],
      "metadata": {
        "id": "1-ZyooFZXQ6b"
      },
      "id": "1-ZyooFZXQ6b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxxxI23hP0LB",
        "outputId": "ed23ce16-d969-4c52-fbdc-39247bee8ffe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ],
      "id": "IxxxI23hP0LB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7-PGU0tP0LC",
        "outputId": "1450ce2c-5046-4425-d50e-fcbb37098c4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datetime\n",
            "  Downloading DateTime-4.5-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52 kB 639 kB/s \n",
            "\u001b[?25hCollecting zope.interface\n",
            "  Downloading zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 251 kB 10.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from datetime) (2022.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zope.interface->datetime) (57.4.0)\n",
            "Installing collected packages: zope.interface, datetime\n",
            "Successfully installed datetime-4.5 zope.interface-5.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datetime"
      ],
      "id": "Z7-PGU0tP0LC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGf7CyCcP0LA",
        "outputId": "b5b226d6-8863-434b-c54e-815d33f71937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235 kB 5.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.4\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode"
      ],
      "id": "RGf7CyCcP0LA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparacion del entorno\n",
        "\n",
        "Se prepara el entorno para ejecutar los tweets.\n",
        "\n",
        "* se importan las librerias\n",
        "\n",
        "* se conecta con el google drive para guardar los archivos\n",
        "\n",
        "* se importan los datos para conectarse con twitter"
      ],
      "metadata": {
        "id": "xg-HCqW-XcNP"
      },
      "id": "xg-HCqW-XcNP"
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar el driver para almacenar los datos\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNgG6lUHrcCg",
        "outputId": "ae405d73-519f-4d71-9b89-5c5e81d154bf"
      },
      "id": "hNgG6lUHrcCg",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "ce521069-6240-4bfa-ad84-7d49ea13374f",
      "metadata": {
        "id": "ce521069-6240-4bfa-ad84-7d49ea13374f",
        "outputId": "47f059ec-2b12-4363-9ce2-9916f98b6f86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "4b1d7fa8-f2fa-416b-b58d-47244192fd55",
      "metadata": {
        "id": "4b1d7fa8-f2fa-416b-b58d-47244192fd55"
      },
      "outputs": [],
      "source": [
        "# Se importan las librerias a utilizar durante todo el proyecto. \n",
        "import requests\n",
        "from requests_oauthlib import OAuth1\n",
        "import pandas as pd\n",
        "\n",
        "from tweepy import OAuthHandler, API, Cursor\n",
        "import json\n",
        "\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from datetime import datetime\n",
        "import unidecode\n",
        "from unicodedata import normalize\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Se leen todos los datos para la conexion desde un archivo json\n",
        "tweets_df = pd.read_json('/content/drive/MyDrive/datos/twitter.json')\n",
        "\n",
        "# Se colocan las variables de trabajo\n",
        "ckey = tweets_df['ckey'][0]\n",
        "csecret = tweets_df['csecret'][0]\n",
        "atoken = tweets_df['atoken'][0]\n",
        "asecret = tweets_df['asecret'][0]\n",
        "Bearer = tweets_df['Bearer'][0]"
      ],
      "metadata": {
        "id": "ACBU4YABeuCI"
      },
      "id": "ACBU4YABeuCI",
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "2642d8b3-083c-4408-9180-0b5f67478680",
      "metadata": {
        "id": "2642d8b3-083c-4408-9180-0b5f67478680"
      },
      "outputs": [],
      "source": [
        "# Se genera una instancia de autenticacion\n",
        "auth = OAuthHandler(ckey, csecret)\n",
        "auth.set_access_token(atoken, asecret)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "4b8ceb1c-99ad-408e-8157-f8ac0f8f4f37",
      "metadata": {
        "id": "4b8ceb1c-99ad-408e-8157-f8ac0f8f4f37"
      },
      "outputs": [],
      "source": [
        "# Se realiza una prueba del api. \n",
        "api = API(auth,\n",
        "        wait_on_rate_limit=True,\n",
        "        wait_on_rate_limit_notify=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d5f482b-57ec-47dd-8e9d-a5b56ac9d53b",
      "metadata": {
        "id": "9d5f482b-57ec-47dd-8e9d-a5b56ac9d53b"
      },
      "source": [
        "# API con request\n",
        "\n",
        "* Se invoca el API para traer los ID de los usuarios\n",
        "\n",
        "* Se invoca el API para traer los 800 registros de cada ID\n",
        "\n",
        "* Se realiza limpieza de los datos y se graban los csv correspondientes\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Se invoca el API que permite buscar a traves del nombre de usuario el ID para las busquedas de las menciones. \n",
        "\n",
        "headers = {'Authorization': f'Bearer {Bearer}'} # Variable de autorizador\n",
        "url = f'https://api.twitter.com/2/users/by' # url de invocacion\n",
        "bancos = '' # variable que guarda toda la respuesta\n",
        "\n",
        "params = {'usernames': 'BBVA_espana,santander_es,caixabank,BancoSabadell,Bankinter',}\n",
        "\n",
        "auth = OAuth1(ckey, csecret,\n",
        "               atoken, asecret)\n",
        "\n",
        "bancos = requests.get(url, params=params, headers=headers).json()\n",
        "bancos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jbgzas90PFxC",
        "outputId": "18004ca2-190c-4dfb-b5c5-aeafe3ecef36"
      },
      "id": "Jbgzas90PFxC",
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': [{'id': '230123496',\n",
              "   'name': 'BBVA en EspaÃ±a',\n",
              "   'username': 'BBVA_espana'},\n",
              "  {'id': '1372470686', 'name': 'Santander EspaÃ±a', 'username': 'santander_es'},\n",
              "  {'id': '270429778', 'name': 'CaixaBank', 'username': 'caixabank'},\n",
              "  {'id': '9980072', 'name': 'Banco Sabadell', 'username': 'BancoSabadell'},\n",
              "  {'id': '86031609', 'name': 'Bankinter', 'username': 'Bankinter'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "4bf6d466-543a-4556-b9f8-6c3b21182ff8",
      "metadata": {
        "id": "4bf6d466-543a-4556-b9f8-6c3b21182ff8"
      },
      "outputs": [],
      "source": [
        "# Se crea una funcion para buscar las menciones por ID, esta funcion devuelve dos DF, \n",
        "# El primero contiene todos los tweets que mencionan el ID del banco que corresponda. \n",
        "# El segundo contiene los usuarios que hacen mencion al ID. \n",
        "\n",
        "def buscar_tweets_mentions(mentions_id, cantidad_tweet=800):\n",
        "\n",
        "    headers = {'Authorization': f'Bearer {Bearer}'} # Variable de autorizador\n",
        "    url = f'https://api.twitter.com/2/users/{mentions_id}/mentions' # url de invocacion\n",
        "    respuesta = '' # variable que guarda toda la respuesta\n",
        "    usuarios = pd.DataFrame() # variable que guarda los usuarios\n",
        "    data = pd.DataFrame()\n",
        "    params = {\n",
        "        'expansions': 'author_id,geo.place_id',\n",
        "        'tweet.fields': 'conversation_id,created_at,lang,public_metrics,possibly_sensitive,source',\n",
        "        'max_results':100} \n",
        "\n",
        "    auth = OAuth1(ckey, csecret,\n",
        "               atoken, asecret)\n",
        "    \n",
        "    for cantidad in range(int(cantidad_tweet/100)):\n",
        "        respuesta = requests.get(url, params=params, headers=headers).json()\n",
        "        data = data.append(respuesta['data'])\n",
        "        usuarios = usuarios.append(respuesta['includes']['users'])\n",
        "        params = {\n",
        "            'expansions': 'author_id,geo.place_id',\n",
        "            'tweet.fields': 'conversation_id,created_at,lang,public_metrics,possibly_sensitive,source',\n",
        "            'pagination_token': respuesta['meta']['next_token'],\n",
        "            'max_results':100}\n",
        "    return data, usuarios"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning\n",
        "\n",
        "Este apartado realiza la limpieza de los datos de text."
      ],
      "metadata": {
        "id": "lEPObQgTTjFa"
      },
      "id": "lEPObQgTTjFa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dejar tweets con idioma espaÃ±ol"
      ],
      "metadata": {
        "id": "FMhVZLtZZrjF"
      },
      "id": "FMhVZLtZZrjF"
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_idioma(df):\n",
        "    return df.loc[df['lang'] == 'es', :]"
      ],
      "metadata": {
        "id": "uvmM3is7Z2rC"
      },
      "id": "uvmM3is7Z2rC",
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwi4O-SKP0LI"
      },
      "source": [
        "## Eliminar menciones"
      ],
      "id": "Fwi4O-SKP0LI"
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "oDEdXPqyP0LI"
      },
      "outputs": [],
      "source": [
        "def remove_link(text):\n",
        "    text = \" \".join(filter(lambda x:x[0:4]!='http', text.split()))\n",
        "    return text"
      ],
      "id": "oDEdXPqyP0LI"
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "qvwZ3CHBP0LJ"
      },
      "outputs": [],
      "source": [
        "def remove_mencion(text):\n",
        "    text = \" \".join(filter(lambda x:x[0]!='@', text.split()))\n",
        "    return text"
      ],
      "id": "qvwZ3CHBP0LJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz6vtqVpP0LL"
      },
      "source": [
        "## Se Eliminan los Caracteres Especiales\n",
        "\n",
        "ðŸ‘‡ Remove punctuation and lower case the text."
      ],
      "id": "Pz6vtqVpP0LL"
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "geo3Q-ebP0LL",
        "outputId": "c89b07ff-7467-4755-e21a-05323611878c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "string.punctuation"
      ],
      "id": "geo3Q-ebP0LL"
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "UwGuNCvCP0LM"
      },
      "outputs": [],
      "source": [
        "def remove_puntuation(text):\n",
        "    mi_puntuacion = '!Â¡\"#$%&\\'()*+,-./:;<=>Â¿?@[\\\\]^_`{|}~'  \n",
        "    for punctuation in mi_puntuacion:\n",
        "        text = text.replace(punctuation, \" \")\n",
        "    return text"
      ],
      "id": "UwGuNCvCP0LM"
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)"
      ],
      "metadata": {
        "id": "pF42QDx5vcbY"
      },
      "id": "pF42QDx5vcbY",
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVuuPimDP0LM"
      },
      "source": [
        "## Covierte en minusculas todo"
      ],
      "id": "WVuuPimDP0LM"
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "9XnxvzdFP0LM"
      },
      "outputs": [],
      "source": [
        "def remove_lower(text1):\n",
        "    text1 = text1.lower()\n",
        "    return text1"
      ],
      "id": "9XnxvzdFP0LM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_6Vw8yhP0LN"
      },
      "source": [
        "## Elimina Acentos"
      ],
      "id": "G_6Vw8yhP0LN"
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "YfwAm8WOP0LN"
      },
      "outputs": [],
      "source": [
        "def cambia_acentuadas(text):\n",
        "    trans_tab = dict.fromkeys(map(ord, u'\\u0301\\u0308'), None)\n",
        "    text = normalize('NFKC', normalize('NFKD', text).translate(trans_tab))\n",
        "    return text"
      ],
      "id": "YfwAm8WOP0LN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKStmbtJP0LN"
      },
      "source": [
        "## Remueve Numeros"
      ],
      "id": "bKStmbtJP0LN"
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "nBa4n-xSP0LN"
      },
      "outputs": [],
      "source": [
        "def remove_numbers(text1):\n",
        "    text1 = ''.join(word for word in text1 if not word.isdigit())\n",
        "    return text1"
      ],
      "id": "nBa4n-xSP0LN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funcion de data_cleaning"
      ],
      "metadata": {
        "id": "oEk8XL-DWpGc"
      },
      "id": "oEk8XL-DWpGc"
    },
    {
      "cell_type": "code",
      "source": [
        "def data_cleaning(df):\n",
        "\n",
        "  df_cleaning = df\n",
        "\n",
        "  # Eliminar elementos duplicados\n",
        "#  df_cleaning.drop_duplicates(inplace=True)\n",
        "\n",
        "  # Eliminar idiomas\n",
        "  df_cleaning = remove_idioma(df_cleaning)\n",
        "\n",
        "  # Eliminar menciones\n",
        "  df_cleaning['text'] = df_cleaning['text'].apply(remove_mencion)\n",
        "\n",
        "  # Eliminar los caracteres iniciales (espacio al principio y finales (espacion al final))\n",
        "  df_cleaning['text'] = df_cleaning['text'].str.strip()\n",
        "\n",
        "  # Elimina los caracteres especiales\n",
        "  df_cleaning['text'] = df_cleaning['text'].apply(remove_puntuation)\n",
        "\n",
        "  # Elimina los emoji\n",
        "  df_cleaning['text'] = df_cleaning['text'].apply(remove_emoji)\n",
        "\n",
        "  # Convierte todo en minusculas\n",
        "  df_cleaning['text'] = df_cleaning['text'].apply(remove_lower)\n",
        "\n",
        "  # Elimina acentos\n",
        "  df_cleaning['text'] = df_cleaning['text'].apply(cambia_acentuadas)\n",
        "\n",
        "  # Elimina numeros\n",
        "  df_cleaning['text'] = df_cleaning['text'].apply(remove_numbers)\n",
        "\n",
        "  return df_cleaning"
      ],
      "metadata": {
        "id": "y3RLQDY5UvI0"
      },
      "id": "y3RLQDY5UvI0",
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejecutar la busqueda "
      ],
      "metadata": {
        "id": "ipYO3_4mwVqn"
      },
      "id": "ipYO3_4mwVqn"
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "c8b1bd1f-8de2-4643-8c31-b62e04c8a3ab",
      "metadata": {
        "id": "c8b1bd1f-8de2-4643-8c31-b62e04c8a3ab"
      },
      "outputs": [],
      "source": [
        "#Se invoca la funcion pasando como dato el ID del usuario que previamente fue cargado. \n",
        "\n",
        "valores = bancos['data'] # Se toman los valores de la lista\n",
        "for i in valores:\n",
        "  id = i['id']\n",
        "  # Se invoca la llamada a la funcion\n",
        "  respuesta_funcion, usuarios_funcion = buscar_tweets_mentions(id)\n",
        "  # Se ajusta la columna de fecha\n",
        "  respuesta_funcion['created_at'] = pd.to_datetime(respuesta_funcion['created_at'])\n",
        "  # Se guardan los dos archivos con el nombre del ID\n",
        "  respuesta_funcion.to_csv(f'/content/drive/MyDrive/IEBS/Global Proyect/datos/{id}.csv')\n",
        "  usuarios_funcion.to_csv(f'/content/drive/MyDrive/IEBS/Global Proyect/datos/user-{id}.csv')\n",
        "  # Se realiza limpieza de variable\n",
        "  respuesta_limpia = data_cleaning(respuesta_funcion)\n",
        "  # Se guardan los dos archivos con el nombre del ID\n",
        "  respuesta_limpia.to_csv(f'/content/drive/MyDrive/IEBS/Global Proyect/datos/cleaning-{id}.csv')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "search twitter.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}